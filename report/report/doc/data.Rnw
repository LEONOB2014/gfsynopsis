Commercial and research catch, effort, and biological data for groundfish are
archived by the Groundfish Data Unit (Fisheries and Oceans Canada, Science
Branch, Pacific Region) and housed in a number of relational databases.
Historical commercial catch and effort data from 1954--2006/2007 are housed in
GFCatch, PacHarvTrawl, PacHarvHL, and PacHarvSable, depending on the fishery and
time period. Modern (2006/2007 to present) commercial catch data are housed in
GFFOS, a groundfish-specific view of the Fishery Operations System (FOS)
database (Fisheries and Oceans Canada, Fisheries and Aquaculture Management,
Pacific Region). Research survey data and commercial biological data from the
1940s to present are housed in GFBio, the Groundfish Biological Samples
database.

We developed a package gfplot for the statistical software R to automate data
extraction from these databases in a consistent, reproducible manner. The
functions extract data using SQL queries, developed with support from the
Groundfish Data Unit, which select and filter for specific data depending on the
analyses for which they will be used. The SQL file names mentioned in this
section can be viewed at
\url{https://github.com/pbs-assess/gfplot/tree/master/inst/sql} and may be
archived in the final version of this document.

We extracted commercial catch with \texttt{get-catch.sql}. All landings and
discards are extracted by species, fishery sector, gear type and year, and are
not filtered in any further way.

We extracted commercial trawl catch per unit effort (CPUE) index data using
\texttt{get-cpue-index.sql} and we filter the data to include only records with
valid start and end dates (Table~\ref{tab:sql-cpue-index}). Catch (kg) and
effort (expressed in hours), year, gear type and Pacific Fishery Management Area
(PFMA) are extracted for each tow. Gear type, PFMA and minimum year are given as
arguments and are set at defaults of bottom trawl, all areas, and 1996,
respectively.

We extracted commercial trawl spatial CPUE data using
\texttt{get-cpue-spatial.sql}, pulling out latitude, longitude, gear type, catch
(kg) and tow time (hours) for every tow by species. The data are filtered to
extract only records with valid start and end dates, to remove records with
erroneous latitude and longitude values, and to include only records from the
groundfish trawl sector with positive tows since 2012 when the trawl footprint
was implemented (Table~\ref{tab:sql-cpue-spatial}).

We extracted commercial hook and line spatial CPUE data using
\texttt{get-cpue-spatial-ll.sql}, which pulls out latitude and longitude, gear
type, catch (pieces) and years for all fishing events (sets, as a unit of
effort) by species. The data are filtered to extract only records with valid
start and end dates, to remove records with erroneous latitude and longitude
values, and to only include records with hook and line gear with non-zero catch.
Data include all records since 2008 after implementation of the Integrated
Groundfish Management Plan (Table~\ref{tab:sql-cpue-spatial-ll}). CPUE is
represented by landed catch in pieces per fishing event (set). Discards are not
included in hook and line spatial CPUE because discarded pieces are not reliably
recorded in all years. Species names are given as an argument to the function.

We extracted survey biomass index data \texttt{get-survey-index.sql}. Calculated
bootstrapped biomass, year and survey series identification code (SSID) are
filtered for active records of the calculated biomass in the database
(Table~\ref{tab:sql-survey-index}). Species and SSID codes are given as
arguments to the function.

We extracted biological data using \texttt{get-survey-samples.sql} and
\texttt{get-comm-samples.sql} for research survey and commercial samples,
respectively. Records of all biological samples are extracted by species,
including available length, weight, age and maturity data. Records include
available metadata including PFMA, fishery, gear type, SSID and survey
identification code (SID, only available for research survey data), survey
sampling types, and sampling protocol codes for maturity and ageing data. Data
are filtered by the \texttt{TRIP\_SUBTYPE\_CODE} to extract either survey
(Table~\ref{tab:sql-surv-samp}) or commercial (Table~\ref{tab:sql-comm-samp})
samples. In addition, samples are designated as one of three sample descriptions
based on combinations of two codes relating to sampling protocols:
\texttt{SPECIES\_CATEGORY\_CODE} (Table~\ref{tab:spp-cat}) and
\texttt{SAMPLE\_SOURCE\_CODE} (Table~\ref{tab:samp-source}). Samples can be
designated as `unsorted samples' in which data were collected for all specimens
in the sample, or `sorted samples' where specimens were sorted or selected into
`keepers', which were sampled, and `discards' which were not sampled:

\begin{resdoclist}

\item Specimens with a species category code of 0 are of unknown species
  category and are not useable. Those with a species category code of 1
  (unsorted) and a sample source code of 0 (unknown) or 1 (unsorted), or with a
  species category code of 5 (remains) or 6 (fish heads only) and a sample
  source code of 1 (unsorted) are classified as `unsorted'.

\item Specimens with a sample source code of 2 (keepers) and a species category
  code of 1 (unsorted), 2 (sorted) or 3 (keepers), or with a species category
  code of 3 (keepers) and a sample source code of 1 (unsorted) are classified as
  `keepers'.

\item Specimens with a species category code of 4 (discards) and a sample source
  code of 1 (unsorted) or 3 (discards), or a sample source code of 3 (discards)
  and a species category code of 1 (unsorted) are `discards'.

\end{resdoclist}

In the synopsis report, we are only including unsorted biological samples. Data
are also filtered by \texttt{SAMPLE\_TYPE\_CODE} to extract only total or random
samples and exclude samples selected by specified criteria.

Age data extracted with the biological sample queries are filtered by
\texttt{AGEING\_METHOD\_CODE} to select current ageing methods verified with the
ageing lab at the Pacific Biological Station in order to remove experimental
ageing methods that may also be recorded in the database
(Table~\ref{tab:valid-age-methods}).

Maturity codes are assigned at the time of sampling following one of the
conventions. The various conventions have different scales and classifications.
We worked with the survey staff, data team, and biologists for the various taxa
to select which codes at and above which an individual fish is considered
`mature' in order to assign a maturity status to each specimen based on
a combination of maturity convention, maturity code, and sex
(Table~\ref{tab:mat-conv-codes}).

The ageing precision data are extracted with \texttt{get-age-precision.sql}.
Data are filtered to bring in only records for which a secondary (precision)
reading was performed by a different technician in addition to the primary
reading (Table~\ref{tab:sql-age-precision}).

\clearpage

\begin{table}[htpb]
\centering
\caption{Description of filters in SQL queries extracting commercial sample data from GFBio with \texttt{get-comm-samples.sql}.}
\label{tab:sql-comm-samp}
{\tabulinesep=1.6mm
\begin{tabu}{>{\raggedright\arraybackslash}m{2.8in}>{\raggedright\arraybackslash}m{3.2in}}
\toprule
Filters                                                                                       & Rationale                                                                                                                                 \\
\midrule
Filtered out \texttt{TRIP\_SUBTYPE\_CODE} \texttt{2, 3} (research trips)                      & To extract only commercial data                                                                                                           \\
Filtered for \texttt{SAMPLE\_TYPE\_CODE} \texttt{1, 2, 6, 7, 8} (random or total)             & To extract only those records of sample type 'random' or 'total'                                                                          \\
Filtered for \texttt{SPECIES\_CATEGORY\_CODE} \texttt{NULL, 0, 1, 3, 4, 5, 6, 7}              & To remove samples sorted on unknown criteria                                                                                              \\
Filtered for \texttt{SAMPLE\_SOURCE\_CODE} \texttt{NULL, 1, 2, 3}                             & To extract both sorted and unsorted samples for later filtration for desired analysis (removes stomach contents samples)                  \\
\bottomrule
\end{tabu}}
\end{table}


\begin{table}[htpb]
\centering
\caption{Description of filters in SQL queries extracting research survey sample data from GFBio with \texttt{get-survey-samples.sql}.}
\label{tab:sql-surv-samp}
{\tabulinesep=1.6mm
\begin{tabu}{>{\raggedright\arraybackslash}m{2.8in}>{\raggedright\arraybackslash}m{3.2in}}
\toprule
Filters                                                                              & Rationale                                                                                                                                          \\
\midrule
Filtered for \texttt{TRIP\_SUBTYPE\_CODE} \texttt{2, 3} (research trips)                      & To extract only research data                                                                                                             \\
Filtered for \texttt{SAMPLE\_TYPE\_CODE} \texttt{1, 2, 6, 7, 8} (random or total)             & To extract only those records of sample type 'random' or 'total'                                                                          \\
Filtered for \texttt{SPECIES\_CATEGORY\_CODE} \texttt{NULL, 0, 1, 3, 4, 5, 6, 7}              & To remove samples sorted on unknown criteria                                                                                              \\
Filtered for \texttt{SAMPLE\_SOURCE\_CODE} \texttt{NULL, 1, 2, 3}                             & To extract both sorted and unsorted samples for later filtration for desired analysis (removes stomach contents samples)                  \\
\bottomrule
\end{tabu}}
\end{table}

\begin{table}[htpb]
\centering
\caption{Description of filters in SQL queries extracting commercial trawl catch and effort data from \texttt{GFFOS.GF\_MERGED\_CATCH} with \texttt{get-cpue-index.sql}}
\label{tab:sql-cpue-index}
{\tabulinesep=1.6mm
\begin{tabu}{>{\raggedright\arraybackslash}m{2.8in}>{\raggedright\arraybackslash}m{3.2in}}
\toprule
Filters                                                                                                                            & Rationale                                                                 \\
\midrule
Filtered for \texttt{END\_DATE} \texttt{IS NOT NULL} AND {START\_DATE} \texttt{IS NOT NULL}                                        & To remove records with missing date                                       \\
Filtered for \texttt{YEAR(FE\_START\_DATE)} = \texttt{YEAR(FE\_END\_DATE)} and \texttt{FE\_END\_DATE} > \texttt{FE\_START\_DATE}   & To remove records with erroneous dates                                    \\
\bottomrule
\end{tabu}}
\end{table}

\begin{table}[htpb]
\centering
\caption{Description of filters in SQL queries extracting commercial trawl spatial catch per unit effort (kg/hr) from \texttt{GFFOS.GF\_D\_OFFICIAL\_CATCH} with \texttt{get-cpue-spatial.sql}}
\label{tab:sql-cpue-spatial}
{\tabulinesep=1.6mm
\begin{tabu}{>{\raggedright\arraybackslash}m{2.8in}>{\raggedright\arraybackslash}m{3.2in}}
\toprule
Filters                                                                                                            & Rationale                                                                 \\
\midrule
Filtered for \texttt{LAT} between 47.8 and 55 and \texttt{LON} between -135 and -122                               & To remove erroneous location records                                      \\
Filtered for \texttt{YEAR(BEST\_DATE)} greater than 2012                                                           & To extract only records since the trawl fishery footprint was established \\
Filtered for \texttt{YEAR(START\_DATE)} = \texttt{YEAR(END\_DATE)} and \texttt{END\_DATE} > \texttt{START\_DATE}   & To remove records with erroneous dates                                    \\
Filtered for \texttt{FISHERY\_SECTOR} = \texttt{GROUNDFISH TRAWL}                                                   & To extract only records in the groundfish trawl fishery                   \\
Filtered for \texttt{ISNULL(LANDED\_ROUND\_KG,0) + ISNULL(TOTAL\_RELEASED\_ROUND\_KG,0)} > 0                            & To extract only records with positive catch                               \\
\bottomrule
\end{tabu}}
\end{table}

\begin{table}[htpb]
\centering
\caption{Description of filters in SQL queries extracting commercial hook and line spatial catch per unit effort (kg/set) from \texttt{GFFOS.GF\_D\_OFFICIAL\_CATCH} with \texttt{get-cpue-spatial-ll.sql}}
\label{tab:sql-cpue-spatial-ll}
{\tabulinesep=1.6mm
\begin{tabu}{>{\raggedright\arraybackslash}m{2.8in}>{\raggedright\arraybackslash}m{3.2in}}
\toprule
Filters                                                                                                            & Rationale                                                                 \\
\midrule
Filtered for \texttt{LAT} between 47.8 and 55 and \texttt{LON} between -135 and -122                               & To remove erroneous location records                                      \\
Filtered for \texttt{YEAR(BEST\_DATE)} greater than or equal to 2008                                               & To extract only records since 2008 after implementation of IFMP           \\
Filtered for \texttt{YEAR(START\_DATE)} = \texttt{YEAR(END\_DATE)} and \texttt{END\_DATE} > \texttt{START\_DATE}   & To remove records with erroneous dates                                    \\
Filtered for \texttt{GEAR} IN \texttt{(HOOK AND LINE, LONGLINE, LONGLINE OR HOOK AND LINE)}                        & To extract only records in the hook and line fishery                      \\
\bottomrule
\end{tabu}}
\end{table}

\begin{table}[htp]
\centering
\caption{Description of filters in SQL queries extracting bootstrapped survey biomass index from \texttt{GFBio} with \texttt{get-survey-index}}
\label{tab:sql-survey-index}
{\tabulinesep=1.6mm
\begin{tabu}{>{\raggedright\arraybackslash}m{2.8in}>{\raggedright\arraybackslash}m{3.2in}}
\toprule
Filters                                                                                                            & Rationale                                                                \\
\midrule
Filter for \texttt{ACTIVE\_IND} 1                                                                                  & To extract only active (useable) bootstrapped index records              \\
\bottomrule
\end{tabu}}
\end{table}

\begin{table}[htp]
\centering
\caption{Description of filters in SQL queries extracting all age records with a precision test reading to determine aging precision from {GFBio} with \texttt{get\_age\_precision.sql}}
\label{tab:sql-age-precision}
{\tabulinesep=1.6mm
\begin{tabu}{>{\raggedright\arraybackslash}m{2.8in}>{\raggedright\arraybackslash}m{3.2in}}
\toprule
Filters                                                                                                            & Rationale                                                                \\
\midrule
Filter for \texttt{AGE\_READING\_TYPE\_CODE} 2, 3                                                                     & To extract primary and precision test readings                           \\
\bottomrule
\end{tabu}}
\end{table}

%
% \begin{table}[htp]
% \centering
% \caption{Description of SQL queries used for data extraction in which no filters were applied and all data were extracted}
% \label{tab:sql-no filters}
% {\tabulinesep=1.6mm
% \begin{tabu}{>{\raggedright\arraybackslash}m{2.8in}>{\raggedright\arraybackslash}m{3.2in}}
% \toprule
% SQL Query                                                                                           & Rationale                                                                                                                \\
% \midrule
% Extract commercial landings from \texttt{GFFOS.GF\_MERGED\_CATCH} with \texttt{get-catch.sql}       & To extract all landings and discards by fishery sector and gear                                                          \\
% Assign maturity status from \texttt{GFFOS.GFBio} with \texttt{maturity\_assignment.sql}             & Designates maturity code at and above which a sample assessed following a given maturity convention is considered mature \\
% \bottomrule
% \end{tabu}}
% \end{table}

<<aging-method-table-setup>>=
library(dplyr)
dc <- "../../data-cache2"
d_survey_sets <- readRDS(file.path(dc, "pbs-survey-sets.rds"))
meta <- d_survey_sets %>%
  select(species_common_name, species_science_name, species_code) %>%
  unique()
f <- system.file("extdata", "ageing_methods.csv", package = "gfplot")
age_methods <- read.csv(f, stringsAsFactors = FALSE, strip.white = TRUE)
names(age_methods) <- tolower(names(age_methods))
age_methods$species_common_name <- tolower(age_methods$species_common_name)
age_methods <- left_join(age_methods, meta, by = "species_common_name")
age_methods$species_common_name <- gfsynopsis:::first_cap(age_methods$species_common_name)
age_methods <- filter(age_methods, type == "A")
age_methods$species_common_name <- gsub("Rockfish Complex", "", age_methods$species_common_name)
age_methods$species_science_name <- gsub(" complex", "", age_methods$species_science_name)
age_methods$species_science_name <- gsub("sebastes aleutianus", "s. aleutianusu",
  age_methods$species_science_name)
age_methods <- select(age_methods, species_common_name, species_science_name,
  species_code, ageing_method_codes)
age_methods <- arrange(age_methods, species_code)
age_methods$species_science_name <- paste0("\\emph{",
  gfplot:::firstup(age_methods$species_science_name), "}")
names(age_methods) <- c("Common name", "Scientific name", "Species code", "Aging codes")
@

<<aging-method-table, results='asis'>>=
print(xtable::xtable(age_methods, caption = "Ageing method codes from GFBio considered valid throughout the synopsis document for groundfish species in British Columbia. The ageing method codes were chosen with the help of the PBS Schlerochronology Lab. 1 $=$ `Otolith Surface Only', 3 $=$ ` Otolith Broken and Burnt', 17 $=$ `Otolith Broken and Baked (Break and Bake)', 6 $=$ `Dorsal Fin XS', 11 $=$ `Dorsal Spine', 12 $=$ `Vertebrae'.", label = "tab:valid-age-methods"), include.rownames = FALSE,
  floating = TRUE, booktabs = TRUE, caption.placement = "top",
  sanitize.text.function = I)
@


<<maturity-table, results='asis'>>=
f <- system.file("extdata", "maturity_assignment.csv", package = "gfplot")
mat <- read.csv(f, stringsAsFactors = FALSE, strip.white = TRUE)
names(mat) <- tolower(names(mat))
names(mat) <- gsub("_", " ", names(mat))
names(mat) <- gfplot:::firstup(names(mat))
mat$`Maturity convention maxvalue` <- NULL
mat <- rename(mat, `Maturity convention description` = `Maturity convention desc`,
  `Mat. conv. code` = `Maturity convention code`)
mat$Sex <- if_else(mat$Sex == 1, "M", "F")

mat <- filter(mat, !`Maturity convention description` %in% "HAKE (AMR simplified)")
mat <- filter(mat, !`Maturity convention description` %in% "HAKE (1977+)")
mat <- filter(mat, !`Maturity convention description` %in% "HAKE (U.S.)")
mat <- filter(mat, !grepl("SABLEFISH", `Maturity convention description`))

print(xtable::xtable(mat, caption = "Maturity convention codes (`Mat. conv. code'), maturity convention descriptions, sex, and the maturity convention value at which a fish is deemed to be mature for the purposes of the synopsis report. Note that fish may be considered mature at other maturity convention values in particular stock assessments where other values are chosen for specific reasons.", label = "tab:mat-conv-codes"), include.rownames = FALSE,
  floating = TRUE, booktabs = TRUE, caption.placement = "top")
@

<<spp-cat-code-table, message=FALSE, warning=FALSE, results='asis'>>=
spp_cat <- readr::read_csv("../tables/spp-category.csv")
spp_cat$`Species Category Description` <-
  gfplot:::firstup(tolower(spp_cat$`Species Category Description`))
spp_cat$`Species Category Description` <-
  gsub("-", "--", spp_cat$`Species Category Description`)
spp_cat$`Species Category Description` <-
  gsub("unk\\.", "unknown", spp_cat$`Species Category Description`)
print(xtable::xtable(spp_cat, caption = "Species category codes lookup table, which
  describes sampling protocols at the catch level.", label = "tab:spp-cat"),
  include.rownames = FALSE, floating = TRUE, booktabs = TRUE,
  caption.placement = "top")
@

<<sample-source-code-table, message=FALSE, warning=FALSE, results='asis'>>=
samp_source <- readr::read_csv("../tables/sample-source.csv")
samp_source$`Sample Source Description` <-
  gfplot:::firstup(tolower(samp_source$`Sample Source Description`))
print(xtable::xtable(samp_source, caption = "Sample source codes lookup table, which
  describes sampling protocols at the sample level.", label = "tab:samp-source"),
  include.rownames = FALSE, floating = TRUE, booktabs = TRUE,
  caption.placement = "top")
@
