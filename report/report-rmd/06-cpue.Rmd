# CPUE INDEX STANDARDIZATION {#sec:cpue-models}

We sought to generate an index of abundance from commercial trawl catch per
unit effort data that was standardized for depth, fishing locality (defined
spatial regions; Figure \@ref(fig:cpue-locality-map)) month, vessel, and
latitude. Before fitting a standardization model, we had to filter and
manipulate the available catch and effort data to generate a dataset
appropriate for model fitting. In the following sections we describe those
decisions for the data from 1996--2017. We then describe our index
standardization model, explore the contribution of the various standardization
components, and identify the effect of including or ignoring space-time
interactions. This model and the following description draws heavily from
a recent assessment of Pacific Cod (in parts copied verbatim), where this model
was first developed and applied [@forrest2018pcod]. For clarity, we include the
full description in this document since the Pacific Cod report remains in
press.

## DEFINING THE 1996--2017 FLEET

Commercial groundfish bottom trawl data from 1996 to present have been recorded
to the fishing-event level in the presence of on-board observers or video
monitoring. Although catch and effort data are available for earlier years for
most species, they are not of the same quality, and for most years do not
contain information on latitude or vessel ID. These earlier data are likely
useful in the assessment of some species, but we have restricted the
presentation of commercial CPUE data in this report to the higher-quality
1996-onwards data to avoid exploring the numerous caveats that would need to be
considered on a species-by-species and decade-by-decade basis. We think the
presentation of historical CPUE is better left to species-specific stock
assessments that can more thoroughly consider these data.

Since we have data on individual vessels for this modern fleet, and in keeping
with previous analyses for Pacific groundfish stocks, we defined a 'fleet' that
includes only vessels that qualify by passing some criteria of regularly
catching Pacific Cod. We follow the approach used in a number of recent BC
groundfish stock assessments by requiring vessels to have caught the species in
at least 100 tows across all years of interest, and to have passed a threshold
of five trips (trips that recorded some of the species) for at least five years
--- all from 1996 to 2017.

## DEFINING THE STANDARDIZATION MODEL PREDICTORS

For depth and latitude, we binned the values into a sequence of bands to allow
for nonlinear relationships between these predictors and CPUE [e.g.
@maunder2004a]. For depth, we binned trawl depth into bands 25m wide. For
latitude, we used bands that were 0.1 degrees wide. To ensure sufficient data
to estimate a coefficient for each factor level, we limited the range of depth
bins to those that fell within the 0.1% to 99.9% cumulative probability of
positive observations and then removed any factor levels (across all
predictors) that contained fewer than 0.1% of the positive observations.

Predictors that are treated as factors in a statistical model need a reference
or base level --- a level from which the other coefficients for that variable
estimate a difference. The base level then becomes the predictor value that is
used in the prediction for the standardized index. We chose the most frequent
factor level as the base level --- a common choice for these types of models
[@maunder2004a]. For example, we set the base month as the most common month
observed in the dataset filtered for only tows where the species was caught.
This choice of base level only affects the intercept or relative magnitude of
our index because of the form of our model (discussed below) and makes no
functional difference in the commercial CPUE timeseries presented in this
report since they are all scaled to that same maximum and displayed without
units.

## A TWEEDIE GLMM INDEX STANDARDIZATION MODEL

Fisheries CPUE data contains both zeros and positive continuous values.
A variety of approaches have been used in the fishery literature to model such
data. One approach has been to fit a delta-GLM (generalized linear model) ---
a model that fits the zero vs. non-zero values with a logistic regression (a
binomial GLM and a logit link) and the positive values with a linear regression
fit to log-transformed data or a Gamma GLM with a log link [e.g. @maunder2004a;
@thorson2013]. The probability of a non-zero CPUE from the first component can
then be multiplied by the expected CPUE from the second component to derive an
unconditional estimate of CPUE. However, this approach suffers from a number of
issues:

1. The delta-GLM approach adds complexity by needing to fit and report on two
   models.
1. In the typical delta-GLM approach, the two models are fit with separate
   links and so the coefficients cannot be combined.
1. The delta-GLM approach assumes independence among the two components [e.g.
   @thorson2017].
1. Perhaps most importantly for our purpose, a delta-GLM in which the two
   models use different links renders a final index in which the index trend is
   dependent on the specific reference levels that the predictors are set to
   [e.g. @maunder2004a].

The Tweedie distribution [@jorgensen1987] solves the above problems [e.g.
@candy2004; @shono2008; @foster2013; @lecomte2013; @thorson2017] but has not
seen widespread use presumably mostly because of the computational expense of
calculating the Tweedie probability density function. Recently, the Tweedie
density function has been introduced to the software TMB [@kristensen2016] and
can be fit relatively quickly to large datasets and for models with many fixed
and random effect parameters either with custom written TMB models or via the
glmmTMB R package [@brooks2017].

In addition to a mean parameter, the Tweedie distribution has two other
parameters: a power parameter $p$ and a dispersion parameter $\phi$. If $1
> p > 2$ then the Tweedie distribution represents a compound distribution
between the Poisson ($p = 1$) and the Gamma distribution ($p = 2$)
(Figure&quot;\@ref(fig:cpue-tweedie-ex)). In fact, the Tweedie is alternatively
referred to as the compound-Poisson-Gamma distribution in this bounded case. We
note, however, that the compound-Poisson-Gamma distribution is often used to
refer to a re-parameterization in which the Poisson and Gamma components are
fit so that they are not assumed to have the same predictive coefficients as
they are in the Tweedie distribution [e.g. @foster2013; @lecomte2013].

We fit the Tweedie GLMM (generalized linear mixed effect model) as

\begin{align}
   (\#eq:cpue-tweedie)
  y_i &\sim \mathrm{Tweedie}(\mu_i, p, \phi), \quad 1 < p < 2,\\
  \mu_i &= \exp \left(
  \bm{X}_i \bm{\beta}
  + \alpha^\mathrm{locality}_{j[i]}
  + \alpha^\mathrm{locality-year}_{k[i]}
  + \alpha^\mathrm{vessel}_{l[i]}
  \right),\\
\alpha^\mathrm{locality}_j &\sim
  \mathrm{Normal}(0, \sigma^2_{\alpha \; \mathrm{locality}}),\\
 (\#eq:cpue-locality-year)
\alpha^\mathrm{locality-year}_k &\sim
  \mathrm{Normal}(0, \sigma^2_{\alpha \; \mathrm{locality-year}}),\\
 (\#eq:cpue-vessel)
\alpha^\mathrm{vessel}_l &\sim
  \mathrm{Normal}(0, \sigma^2_{\alpha \; \mathrm{vessel}}),
\end{align}

where $i$ represents a single tow, $y_i$ represents the catch (kg) per unit
effort (hours trawled), $\bm{X_i}$ represents a vector of fixed-effect
predictors (depth bins, months, latitude bins), $\bm{\beta}$ represents
a vector of coefficients, and $\mu_i$ represents the expected CPUE in a tow.
The random effect intercepts ($\alpha$ symbols) are allowed to vary from the
overall intercept by locality $j$ (\(\alpha^\mathrm{locality}_j\)),
locality-year $k$ (\(\alpha^\mathrm{locality-year}_k\)), and vessel $l$
(\(\alpha^\mathrm{vessel}_l\)) and are constrained by normal distributions with
respective standard deviations denoted by $\sigma$ parameters.

We can then calculate the standardized estimate of CPUE for year $t$, $\mu_t$,
as

\begin{equation}
  \mu_t = \exp \left(\bm{X}_t \bm{\beta} \right)
\end{equation}

where $\bm{X_t}$ represents a vector of predictors set to the reference ($r$)
levels with the year set to the year of interest. Because each of the $\alpha$
random intercepts is set to zero, the index is predicted for an average
locality, locality-year, and vessel. We estimated the fixed effects with
maximum marginal likelihood while integrating over the random effects with the
statistical software TMB via the R package glmmTMB. We used standard errors
($\mathrm{SE}$) as calculated by TMB on $\log (\mu_t)$ via the generalized
delta method. We then calculated the 95\% Wald confidence intervals as $\exp
(\mu_t \pm 1.96 \mathrm{SE}_t)$. For comparison, we calculated an
unstandardized timeseries by summing the catch each year and dividing it by the
summed effort each year (the dashed lines on the figure pages).

<!--
## COMMERCIAL CPUE STANDARDIZATION EXAMPLE

The Tweedie GLMM index standardization models fit the data relatively well
(Figure \@ref(fig:cpue-quantile-residuals)). The Tweedie $p$ parameters tended
to be around $1.6$, indicating a distribution roughly midway between the Poisson
and Gamma distributions and the $\phi$ parameters indicated relatively dispersed
observations (Table \@ref(tab:cpue-pars)). There was considerably more
variability across the locality and locality-year random effects than the vessel
random effects (Table \@ref(tab:cpue-pars)).

For the 1956--1995 time period, depth and locality had a moderate effect on the
standardized CPUE index for 3CD, but the standardized and unstandardized series
differed little in 5ABCD (Figure \@ref(fig:cpue-index-ts-hist)). Accounting for
either depth or locality reduced the 3CD CPUE in the 1970s and increased the
CPUE from the mid 1980s to 1995. Accounting for depth also reduced a spike in
CPUE in 3CD in the mid 1960s. For the 1996--2017 time period, depth and
latitude had the largest effect on the standardized index, and again had
a larger effect in 3CD than 5ABCD (Figure \@ref(fig:cpue-index-ts-modern)).
Accounting for depth or latitude somewhat decreased the CPUE index for two to
three years before and after 2010 and this effect carried through to the
standardization model with all covariates.

Accounting for locality-year interactions had little effect on the shape of the
standardized indices with the exception of a slight change in shape 2014--2015
for the modern dataset in 5ABCD (Figure \@ref(fig:cpue-int-test-plot)). The
main effect of including the locality-year random effect interactions was to
increase the width of the confidence intervals in all areas and time periods.
We can examine the contribution of all the fixed and random effect parameters
via coefficient plots (historical: Figures \@ref(fig:cpue-coef-plot1),
\@ref(fig:cpue-coef-plot2), \@ref(fig:cpue-coef-plot3); modern: Figures
\@ref(fig:cpue-coef-plot1-modern), \@ref(fig:cpue-coef-plot2-modern),
\@ref(fig:cpue-coef-plot3-modern)).

## SPACE-TIME (LOCALITY-YEAR) INTERACTIONS

To test the effect of including or not including space-time interactions when
such interactions are or are not present, we performed a simulation test. While
a full simulation test with many stochastic iterations and a range of parameter
values is beyond the scope of this appendix, we think this simple simulation
remains instructive. We parameterized our simulation to approximately match the
parameters estimated from observed data. Our simulation included 20 years of
data; 12 localities with their effects ($\alpha^\mathrm{locality}_{j}$) in log
space drawn from a normal distribution with a standard deviation of 0.3 and
mean 0; optional year-locality random effects
($\alpha^\mathrm{locality-year}_{j}$)  drawn from a distribution with
a standard deviation of 0.5 and mean of 0; 10 observations per year per
locality; a true known CPUE index that, in log space, followed an
auto-regressive process with correlation of 0.3 at lag 1, standard deviation of
1 and a mean of 2; and Tweedie parameters of $p = 1.6$ and $\phi = 5$. We
generated versions of this dataset with and without the locality-year
interactions and then fit standardization models to those datasets that either
allowed for or ignored locality-year interactions.

For the real data, including locality-year random effects allowed for each
locality to have a trend that deviates slightly from the overall trend (Figure
\@ref(fig:cpue-re-int-ts)). Omitting these locality-by-year random effects, on
the other hand, assumed that the CPUE trend is identical in shape and only
deviated in magnitude across localities (Figure \@ref(fig:cpue-re-no-int-ts)).
Ignoring these space-time interactions can result in confidence intervals that
are substantially too narrow if the trends are not in fact identical across
space (Figure \@ref(fig:cpue-sim-test-tweedie-glmm-plot)). Furthermore,
allowing for the interactions has no qualitative effect on model performance or
coverage if the interactions are not present (Figure
\@ref(fig:cpue-sim-test-tweedie-glmm-plot)).

Fitting a proper geostatistical spatiotemporal standardization model would be
an alternative to these locality-year random effects [e.g. @thorson2015b;
@monnahan2018]. For this assessment, we chose to model spatial variation
through the DFO localities to maintain consistency with previous assessments in
this region. However, in the future we may explore a spatiotemporal
standardization model.

-->

```{r cpue-loaded-data}
library(dplyr)
d_cpue <- readRDS(here::here("report/data-cache/cpue-index-dat.rds"))
d_cpue$locality_code <- paste(d_cpue$major_stat_area_code,
  d_cpue$minor_stat_area_code, d_cpue$locality_code, sep = "-")
locality_count <- d_cpue %>%
  filter(latitude >= 45) %>%
  mutate(year = lubridate::year(best_date)) %>%
  filter(year >= 1996, year <= 2017) %>%
  group_by(locality_code) %>%
  summarize(n = n()) %>%
  arrange(-n)
```

(ref:cpue-locality-map-cap) Top 100 DFO localities (by fishing event account) used in the commercial CPUE standardization models. In total there are `r nrow(locality_count)` possible localities recorded in the data set.

```{r cpue-locality-map, fig.cap="(ref:cpue-locality-map-cap)", fig.asp=0.9}
gfplot:::plot_dfo_localities(top_n(locality_count, 75)$locality_code)
```

```{r cpue-tweedie-ex, fig.asp=0.7, fig.cap="Example density functions for the Tweedie distribution. The symbol $\\phi$ (written as phi in this figure) represents the dispersion parameter, $p$ represents the power parameter, and $\\mu$ represents the mean. Note that the spike in density that is seen towards the left of the panels is at a value of 0 on the x axis."}
plot_tweedie_ex <- function(df, max = 15) {
  xx <- seq(0, max, length.out = 1000)
  out <- plyr::mdply(df, function(mu, power, phi) {
    data.frame(x = xx,
      y = tweedie::dtweedie(y = xx, mu = mu, power = power, phi = phi))
  }) %>%
    mutate(phi = paste("phi =", phi)) %>%
    mutate(power = paste("p =", power)) %>%
    mutate(mu = paste("μ =", mu))

  ggplot(out, aes(x, y, colour = mu)) +
    geom_line() +
    facet_grid(power~phi, scales = "free") +
    gfplot::theme_pbs() +
    labs(colour = "μ") +
    xlab("Value") + ylab("Density") +
    coord_cartesian(expand = FALSE, xlim = c(-0.2, max(out$x))) +
    scale_colour_brewer(palette = "Dark2") +
    scale_fill_brewer(palette = "Dark2")
}

df <- expand.grid(power = c(1.2, 1.6, 1.8), mu = c(1, 3, 6), phi = c(0.5, 1, 2))
plot_tweedie_ex(df)
```


```{r cpue-model-load}
cpue_model <- readRDS(here::here("report/cpue-cache/petrale-sole-5AB-model.rds"))
```

```{r cpue-fleet-load}
# d_cpue <- readRDS(here::here("report/data-cache/cpue-index-dat.rds"))
d_cpue_pred <- gfplot::predict_cpue_index_tweedie(cpue_model, center = FALSE)
d_cpue_pred$formula_version <- "Full standardization"
if (file.exists(here::here("report/cpue-cache/petrale-sole-5AB-fleet.rds")))
  d_fleet <- readRDS(here::here("report/cpue-cache/petrale-sole-5AB-fleet.rds"))
```

```{r cpue-int-lines, fig.width=6, out.width="4in", fig.cap="Locality-specific CPUE index trends for a standardization model that allows for locality-year (space-time) interactions. The coloured lines indicate the locality-specific estimates with all other predictors set to their base levels. The black line and shaded ribbon indicate the overall average annual CPUE and 95\\% CI, respectively."}
if (exists("d_fleet"))
  plot_cpue_spaghetti(
    model = cpue_model,
    fleet = d_fleet,
    index_data = d_cpue_pred,
    era = "modern")
```

(ref:caption-cpue-quantile-residuals) Histograms of randomized quantile
residuals [@dunn1996] for the CPUE GLMM standardization models. The histograms
illustrate the distribution of 10,000 randomly selected randomized quantile
residuals. The dashed lines show the probability density for a normal
distribution with the same standard deviation.

```{r cpue-quantile-residuals, fig.width=6, out.width="4in", fig.cap="(ref:caption-cpue-quantile-residuals)"}
qr <- gfplot::qres_tweedie(cpue_model, response = "cpue")
gfplot::plot_qres_histogram(qr)
```

\clearpage

