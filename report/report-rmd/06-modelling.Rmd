# MODELLING DETAILS

## SURVEY RELATIVE BIOMASS INDEX TRENDS {#sec:survey-trend-models}

Details on the design of the various surveys referenced in this report can be
found in the following documents:

1. Synoptic Survey, Queen Charlotte Sound (SYN QCS):  [@wyeth2018synqcs]

1. Synoptic Survey, West Coast Vancouver Island (SYN WCVI):
  [@wyeth2017synwcvi]

1. Synoptic Survey, Hecate Strait (SYN HS): [@wyeth2018synhs]

1. Synoptic Survey, West Coast Haida Gwaii (SYN WCHG):
  [@wyeth2018synwchg]

1. Hard Bottom Longline Survey, Outside (HBLL OUT): [@dfo2018ifmp]

1. Hard Bottom Longline Survey, Inside (HBLL INS): [@lochead2004irf]

1. Hecate Strait Multispecies Assemblage Survey (MSA HS):
  [@fargo1984hsmsa,westrheim1984hsmsa]

1. International Pacific Halibut Commission fishery independent survey (IPHC
  FISS): [@flemming2012iphc]

We calculated the trawl and longline survey relative biomass index trends from
the same design-based bootstrap approach used in recent BC groundfish stock
assessment reports. The code to perform the calculations was originally written
by Norm Olsen at Pacific Biological Station and is automatically applied to the
available survey data to populate the GFBio database. We extracted the relative
biomass values directly from GFBio. Nonetheless, we have included the relevant
equations below for clarity.

### TRAWL SURVEYS

For all trawl surveys, and for a given species, we calculated the relative
biomass density $B$ in year $y$ as:

\begin{equation}
  B_y = \sum_{i = 1}^k C_{y,i} A_i
\end{equation}

where $C_{y,i}$ represents the mean CPUE in kg/km^2^ for the
species in year $y$ and stratum $i$, $A_i$ represents the area of stratum $i$ in
km^2^, and $k$ represents the number of strata. We calculated
the CPUE ($C_{y,i}$) for a given species in year $y$ and stratum $i$ as:

\begin{equation}
  C_{y,i} = \frac{\sum_{j = 1}^{n_{y,i}} \left( W_{y,j} / D_{y,j} w_{y,j}\right)}{n_{y,i}}
\end{equation}

where $W_{y,j}$ represents the catch weight (kg) for the species in year $y$,
stratum $i$, and tow $j$; $D_{y,j}$ represents the distance travelled in km by
tow $j$ in year $y$; $w_{y,j}$ represents the net opening width in km for year
$y$ and tow $j$; and $n_{y,i}$ represents the number of tows in year $y$ and
stratum $i$.

### LONG-LINE SURVEYS

For all long-line surveys, and for a given species, we calculated the relative
biomass density $B$ in year $y$ as:

\begin{equation}
  B_y = \sum_{i = 1}^k C_{y,i} A_i
\end{equation}

where $C_{y,i}$ represents the mean CPUE in parts (fish) per
km\textsuperscript{2} for the species in year $y$ and stratum $i$, $A_i$
represents the area of stratum $i$ in km^2^, and $k$ represents
the number of strata. We calculated the CPUE ($C_{y,i}$) for a given species in
year $y$ and stratum $i$ as:

\begin{equation}
  C_{y,i} = \frac{\sum_{j = 1}^{n_{y,i}} \left( N_{y,j} / H_{y,j} w_{y,j}\right)}{n_{y,i}}
\end{equation}

where $N_{y,j}$ represents the number of fish caught for the species in year
$y$, stratum $i$, and set $j$; $H_{y,j}$ represents the number of hooks $\times$
the hook spacing in km in set $j$ in year $y$; $w_{y,j}$ represents an arbitrary
swept width of 30 feet or 0.009144 km for year $y$ and tow $j$; and $n_{y,i}$
represents the number of sets in year $y$ and stratum $i$. The hook spacing is
18 feet or 0.0054864 km for the IPHC survey and 8 feet or 0.0024384 km for
the inside and outside HBLL surveys.

### BOOTSTRAPPED CONFIDENCE INTERVALS

We calculated bootstrap confidence intervals on $B_y$ by repeatedly calculating
$B_y$ given the above equations but each time re-sampling, with replacement, from
the available tows within each strata. We drew 1000 bootstrap replicates of
$B_y$, $B_y^{\mathrm{rep}}$, and calculated 95% quantile-based confidence
intervals on $B_y^{\mathrm{rep}}$.

## SPATIAL MODELLING OF SURVEY BIOMASS {#sec:spatial-modeling}

We modelled the expected biomass density in space for each species using
geostatistical models applied to data from the fisheries independent bottom
trawl and long line surveys (e.g. Figure TODO). Our modeling approach is
consistent with recent models used for spatiotemporal index standardization of
fish populations [e.g. @shelton2014; @ward2015; @thorson2015; @thorson2016].
Such models have been shown, for example, to improve estimates of rockfish
abundance and distribution [@shelton2014] and improve precision when estimating
relative abundance indices for groundfish [@thorson2015]. Our specific model
follows the implementation in @shelton2018 closely and is implemented with INLA
[@rue2009; @lindgren2015] via R [@rcoreteam2018], which enables rapid Bayesian
model fitting for these large spatial data sets via the integrated nested
Laplace approximation of the posterior distribution.

At a high level, these models predict relative biomass in space as a continuous
process with a quadratic effect for bottom depth, a random effect spatial
surface that represents an amalgamation of spatial processes not explicitly
included in the model, and an observation error component. After fitting the
model to survey sets from trawl or longline surveys, the model is then
projected to a fine-scale 2 $\times$ 2 km grid in a UTM 9 projection to derive
estimates of biomass throughout the survey domain.

Similarly to the catch per unit effort index standardization (explained in
Section TODO), we fit these models as 'delta' models that combine a model
explaining the probability of occurrence of a species in a set with a model
explaining the expected biomass in a set given that the species has been
caught. The probability from the first model is multiplied by the expected
biomass from the second model to derive the overall estimate of relative
biomass.

We fit the binomial occurrence models (denoted with a superscript $B$), which
predict the probability of occurrence of a given species at location $s$,
$\pi_s^B$ as a logistic GLMM (Generalized Linear Mixed-effects Model):

$$\begin{aligned}
  y_\mathbf{s}^B &\sim \mathrm{Binomial}(\pi_\mathbf{s}^B)\\
  \mathrm{logit} \left(\pi_\mathbf{s}^B \right) &= \bm{X}_\mathbf{s}^B \bm{\beta}^B + \epsilon_\mathbf{s}^B,\end{aligned}$$

where

$$\mathrm{logit}\left(\pi \right) = \log \left( \frac{\pi}{1 - \pi} \right).$$

The spatial random effects $\epsilon_\mathbf{s}^B$ are assumed to be drawn from
a multivariate normal distribution with covariance matrix
$\bm{\Phi}_\mathbf{s}^B$ that is centered on zero:

$$\epsilon_\mathbf{s}^B \sim \mathrm{MVNormal} \left( \bm{0}, \bm{\Phi}_\mathbf{s}^B \right).$$

We fit the positive model (denoted with a superscript $G$ for Gamma) as a Gamma
GLMM with a similar structure for the spatial random effects:

$$\begin{aligned}
  y_\mathbf{s}^G &\sim \mathrm{Gamma} \left( \bm{\mu}_\mathbf{s}^G, \phi^G \right)\\
  \log \left( \bm{\mu}_\mathbf{s}^G \right) &= \bm{X}_\mathbf{s}^G \bm{\beta}^G + \epsilon_\mathbf{s}^G\\
  \epsilon_\mathbf{s}^G &\sim \mathrm{MVNormal} \left( \bm{0}, \bm{\Phi}_\mathbf{s}^G \right)\end{aligned}$$

We modeled the covariance for the spatial random effects in both the occurrence
and positive models as a function of distance with the Matern function. The
Matérn function describes the covariance between spatial locations $s_j$ and
$s_k$ as:

$$\Phi\left( s_j,s_k \right) = \tau^2/\Gamma(\nu)2^{\nu - 1}
    (\kappa d_{jk})^\nu K_\nu \left( \kappa d_{jk} \right),$$

where $\tau^2$ represents the spatial variance, $\Gamma$ represents the Gamma
function, $K_\nu$ represents the Bessel function, $d_{jk}$ represents the
Euclidean distance between locations $s_j$ and $s_k$, and $\kappa$ represents
a scaling parameter that is estimated. The parameter $\nu$ controls the
smoothness of the covariance function. We set $\nu = 3/2$, as is commonly done
when fitting similar spatial models [e.g. @ward2015; @thorson2015; @ono2016;
@shelton2018], which lets the covariance function be more flexible than an
exponential covariance function but still be differentiable [@rasmussen2004].

At this stage we drew 1000 samples from the posterior distributions of
$\pi_\mathbf{s}^B$ and $\mu_\mathbf{s}^G$ and combined them to estimate the
unconditional posterior distribution of expected biomass in each point on
a 2x2km spatial grid, $\mu_\mathbf{s}$ as:

$$\mu_\mathbf{s} = \pi_\mathbf{s}^B \cdot \mu_\mathbf{s}^G.$$

For the purposes of the maps, we summarized the posteriors by their median
values. See Figures TODO and TODO for examples of these sub-component binary
and positive models and the combined model. We placed Normal(0, 5) priors on
coefficients relating standardized depth and standardized depth squared to the
responses and Normal(0, 20) priors on the intercepts. Note that our notation is
Normal(mean, standard deviation) not Normal(mean, variance) following the
convention used by the Bayesian software Stan [@rstan2018].

We fit the four synoptic survey data sets separately, because only two of the
surveys are conducted each year and the surveys are disjointed in space and
time. We combined the predictions to generate the map plots, but labelled the
years the various surveys were conducted in. Currently, we are fitting the HBLL
surveys as one dataset, although we plan to separate the north and south
surveys since they are also conducted in offset years. We have projected the
IPCC model estimates back to the original station locations for simplicity and
to avoid having to derive a reasonable survey domain polygon.

```{r sdmTMB-data}
library(dplyr)
library(ggplot2)
library(sdmTMB)
d <- readRDS(here::here("report/data-cache/pacific-cod.rds"))
d <- d$survey_sets
dat <- gfplot:::tidy_survey_sets(d, "SYN QCS", years = 2017)
dat <- mutate(dat, density = density*1000*1000)
dat <- filter(dat, !is.na(depth))
dat <- gfplot:::scale_survey_predictors(dat)
dat <- select(dat, -X10, -Y10)

grid_locs <- gfplot:::make_prediction_grid(filter(dat, year == 2017),
  survey = "SYN QCS", cell_width = 1.5)$grid
grid_locs <- rename(grid_locs, depth = akima_depth)
grid_locs$year <- NULL
```

```{r sdmTMB-spde, fig.width=9, out.width="3.7in", fig.cap="Red indicates knots. Open circles represent the locations of the survey sets. TODO"}
spde <- make_spde(dat$X, dat$Y, n_knots = 200)
plot_spde(spde)
```

```{r sdmTMB-model}
m <- sdmTMB(
  data = dat, formula = density ~ depth_scaled + depth_scaled2,
  time = "year", spde = spde, family = tweedie(link = "log"),
  silent = TRUE, anisotropy = FALSE
)
```

```{r sdmTMB-resids, fig.width=6, out.width="4in", fig.cap="Spatial residuals TODO"}
dat$resids <- residuals(m) # randomized quantile residuals
# hist(dat$resids)
# qqnorm(dat$resids);abline(a = 0, b = 1)
ggplot(dat, aes(X, Y, col = resids)) + scale_colour_gradient2() +
  geom_point() + coord_fixed() +
  xlab("Easting") + ylab("Northing") +
  scale_colour_gradient2(midpoint = 0,
    high = scales::muted("red"),
    mid = "white",
    low = scales::muted("blue")) +
  labs(colour = 'Residual')
```

```{r sdmTMB-preds, fig.width=6, out.width="4in"}
predictions <- predict(m, newdata = grid_locs)
plot_map <- function(.dat, column) {
  ggplot(.dat, aes_string("X", "Y", fill = column)) +
    geom_raster() +
    coord_fixed(expand = FALSE) +
    xlab("Easting") + ylab("Northing") +
    theme(legend.position = "bottom") +
    geom_point(data = dat, aes(X, Y, size = density), pch = 21, inherit.aes = FALSE) +
    scale_size_area() +
    guides(size = FALSE)
}
```

```{r sdmTMB-plot-depth}
g_depth <- plot_map(grid_locs, "depth") +
  scale_fill_viridis_c(trans = "sqrt", option = "A", direction = -1) +
  ggtitle("Depth") +
  labs(fill = 'Depth (m)')
```

```{r sdmTMB-plot-combined}
g_sdm1 <- plot_map(predictions$data, "exp(est)") +
  scale_fill_viridis_c(trans = "sqrt", option = "C") +
  ggtitle("Prediction (depth effects + spatial random effects)") +
  labs(fill = 'Biomass estimate\nkg/km^2')
```

```{r sdmTMB-plot-fe}
g_sdm2 <- plot_map(predictions$data, "exp(est_fe)") +
  ggtitle("Prediction (depth effects only)") +
  scale_fill_viridis_c(trans = "sqrt", option = "D") +
  labs(fill = 'Biomass estimate\nkg/km^2')
```

```{r sdmTMB-plot-re}
g_sdm3 <- plot_map(predictions$data, "est_re_s") +
  ggtitle("Spatial random effects") +
  scale_fill_gradient2(midpoint = 0,
    high = scales::muted("red"),
    mid = "white",
    low = scales::muted("blue")) +
  labs(fill = 'Deviation from expected\nbiomass in log space')
```

```{r sdmTMB-maps-combined, fig.width=9, fig.asp=1, out.width="6in", fig.cap="Example spatial model components in Queen Charlotte Sound for Pacific Cod."}
cowplot::plot_grid(g_depth, g_sdm2, g_sdm3, g_sdm1)
```


\clearpage

## CPUE INDEX STANDARDIZATION {#sec:cpue-models}

We present two commercial bottom trawl catch per unit effort (CPUE) indices in
the synopsis report: a 'raw' unstandardized timeseries and a 'standardized' time
series (e.g. Figure \@ref(fig:trawl-cpue-index). The standardized time series
follows the approach commonly employed for British Columbia groundfish stock
assessments of using a Generalized Linear Model (GLM) to account for the
confounding effects of month, depth, latitude, vessel, and DFO locality
(predesignated historical geographical locations) when calculating an annual
index value. We do this by fitting two GLMs: one to data representing whether or
not the species of interest (e.g. Pacific Cod for a Pacific Cod CPUE index) is
caught in a given tow (the 'binary' model),
and a second model to data representing the CPUE conditional on a tow having caught
at least one of that species of interest (the 'lognormal' model). This approach is
sometimes called a delta-lognormal GLM. These two model components can then be
combined to derive the final estimate of CPUE for a given year at a consistent
value for all the predictors, i.e. a consistent month, depth, latitude, vessel,
and DFO locality.

For depth and latitude, we binned the values into a sequence of bands to allow
for nonlinear relationships between these predictors and the response. For
latitude, we used bands that are 0.2 degrees wide, start at the 2% quantile of
the latitude values for the specific region and end at the 98% quantile of the
latitude values. We used this quantile method to algorithmically account for
outlying values that were often data recording errors and could cause problems
when fitting the models. We rounded the lowest latitude bin down to the nearest
0.2 latitude value and rounded to the upper latitude bin up to the nearest 0.2
latitude value. For depth, we used the fishing capture depth binned into bands
that are 50m wide. The bins start at the 1% quantile of the depth values for
the specific region and end at the 99% quantile of the depth values. We rounded
the lowest and highest bin values to 50m values similarly to the process for
the latitude bins as described above.

Due to the multispecies nature of the BC groundfish fishery, it is necessary to
define rules about which vessels should be considered part of a 'fleet'
with which to calculate a CPUE index. We follow the approach used in a number of
recent BC groundfish stock assessments by requiring vessels to have caught the
species in a certain number of tows across all years of interest, and to have
passed a certain threshold of positive trips (trips that recorded some of the
species) for a certain number of years. Our current implementation requires a
vessel to have recorded at least 100 positive tows since 1996 and to have
recorded at least four positive trips in at least four years since 1996. These
decisions are in line with recent BC groundfish stock assessments
[e.g. @starr2017pollock].

We fit the binomial model (denoted with a superscript $B$) as a logistic
regression:

\begin{align}
  y_i^B &\sim \mathrm{Binomial}(\pi_i^B)\\
  \mathrm{logit}\left(\pi_i^B\right) &= \bm{X}_i^B \bm{\beta}^B,
\end{align}

and $i$ represents a single tow, $y_i$ represents either a 1 if a tow caught the
species or a 0 if it did not, $\bm{X^B_i}$ represents a vector of predictors,
$\bm{\beta^B}$ represents a vector of coefficients, and $\pi_i^B$ represents the
estimated probability of observing the species in a tow. Details to follow on
the specific depth and latitude bands chosen.

We fit the lognormal model (denoted with a superscript $L$) as a linear model
fit to log-transformed response data:

\begin{equation}
  \log \left(y_i^L\right) \sim \mathrm{Normal} \left(\bm{X}_i^L \bm{\beta}^L, \sigma \right),
\end{equation}

where the symbols can be interpreted as before except that $y_i^L$ represents
the CPUE in kg per hour towed for a tow that did catch at least one of the
species, and $\sigma$ represents the standard deviation of unexplained residual
error.

We can then calculate the standardized estimate of CPUE for year $t$, $\mu_t$ as:

\begin{equation}
  \mu_t = \mathrm{logit}^{-1} \left(\bm{X}_r^B
    \bm{\beta}^B \right) \cdot \exp \left(\bm{X}_r^L \bm{\beta}^L \right)
\end{equation}

or

\begin{equation}
  \mu_t = \pi_t^B \cdot \exp \left(\bm{X}_r^L \bm{\beta}^L \right)
\end{equation}

where $\bm{X_r}$ represents a vector of predictors set to the reference ($r$)
levels with the year set to the year of interest. We chose the reference levels
as the most frequent level of each predictor in the positive-only data
[@maunder2004]. For example, we set the reference month as the most common
month observed in the dataset filtered for only tows where the species was
caught. This will have a minor effect on the shape of the final CPUE index
because of the multiplication of the binary and positive components.

Recent BC groundfish stock assessments have used a bootstrap approach to derive
estimates of uncertainty around standardized CPUE timeseries. This proved to be
computationally unfeasible to run for all the management areas and stocks in
this synopsis report. Therefore we wrote the model in the statistical software
TMB [@kristensen2016] and use standard errors ($\mathrm{SE}$) as calculated
by TMB on $\log (\mu_t)$ via the Delta method as is commonly done for such
models [e.g. @thorson2015]. We then calculated the 95% confidence
intervals as $\exp (\mu_t \pm 1.96 \mathrm{SE}_t)$.

We calculated the 'raw' unstandardized timeseries is calculated using a similar
procedure but without any of the covariates other than a factor predictor for
each year. This is equivalent to calculating the geometric mean of CPUE each
year.

We tested our implementation of this index standardization model against
simulated data to ensure that (1) it can generate unbiased annual estimates and
(2) the confidence intervals have the correct coverage, i.e. the confidence
intervals contain the true known value at the expected frequency of 95%. We
also compared our estimates qualitatively to recent estimates from similar
models in published assessments to ensure we derived similar timeseries.

For the simulation testing, as examples, we present results for two simulations
with 10 vessels, each vessel recording data from 15 tows, 20 years of data, and
lognormal observation error with standard deviation 0.35 (i.e., approximately
a CV of 0.35). The standardization model then accounts for vessel ID in both
a binary and positive component model. The delta model derives an unconditional
estimate of CPUE after combining the two component models. The parameter
estimates from the component models regularly fall along the one-to-one line of
unbiased and accurate prediction (e.g. Fig. \@ref(fig:cpue-sim-cross-val)) and
the unconditional estimates of CPUE and their confidence intervals regularly
include the true values with correct coverage (e.g.
Fig. \@ref(fig:cpue-sim-ts-val)).

```{r cpue-model-load}
cpue_model <- readRDS(here::here("report/cpue-cache/petrale-sole-5AB-model.rds"))
```

```{r cpue-fleet-load}
# d_cpue <- readRDS(here::here("report/data-cache/cpue-index-dat.rds"))
d_cpue_pred <- gfplot::predict_cpue_index_tweedie(cpue_model, center = FALSE)
d_cpue_pred$formula_version <- "Full standardization"
if (file.exists(here::here("report/cpue-cache/petrale-sole-5AB-fleet.rds")))
  d_fleet <- readRDS(here::here("report/cpue-cache/petrale-sole-5AB-fleet.rds"))
```

```{r cpue-int-lines, fig.width=6, out.width="4in", fig.cap="Locality-specific CPUE index trends for a standardization model that allows for locality-year (space-time) interactions. The coloured lines indicate the locality-specific estimates with all other predictors set to their base levels. The black line and shaded ribbon indicate the overall average annual CPUE."}
if (exists("d_fleet"))
  plot_cpue_spaghetti(
    model = cpue_model,
    fleet = d_fleet,
    index_data = d_cpue_pred,
    era = "modern")
```

```{r cpue-tweedie-ex, fig.asp=0.7, fig.cap="Example density functions for the Tweedie distribution. The symbol $\\phi$ (written as phi in this figure) represents the dispersion parameter, $p$ represents the power parameter, and $\\mu$ represents the mean. Note that the spike in density that is seen towards the left of the panels is at a value of 0 on the x axis."}
plot_tweedie_ex <- function(df, max = 15) {
  xx <- seq(0, max, length.out = 1000)
  out <- plyr::mdply(df, function(mu, power, phi) {
    data.frame(x = xx,
      y = tweedie::dtweedie(y = xx, mu = mu, power = power, phi = phi))
  }) %>%
    mutate(phi = paste("phi =", phi)) %>%
    mutate(power = paste("p =", power)) %>%
    mutate(mu = paste("μ =", mu))

  ggplot(out, aes(x, y, colour = mu)) +
    geom_line() +
    facet_grid(power~phi, scales = "free") +
    gfplot::theme_pbs() +
    labs(colour = "μ") +
    xlab("Value") + ylab("Density") +
    coord_cartesian(expand = FALSE, xlim = c(-0.2, max(out$x))) +
    scale_colour_brewer(palette = "Dark2") +
    scale_fill_brewer(palette = "Dark2")
}

df <- expand.grid(power = c(1.2, 1.6, 1.8), mu = c(1, 3, 6), phi = c(0.5, 1, 2))
plot_tweedie_ex(df)
```

\clearpage

(ref:caption-cpue-quantile-residuals) Histograms of randomized quantile residuals [@dunn1996] for the CPUE GLMM standardization models. The histograms illustrate the actual density distribution of 10,000 randomly selected randomized quantile residuals. The dashed lines show the probability density for a normal distribution with the same standard deviation.

```{r cpue-quantile-residuals, fig.cap="(ref:caption-cpue-quantile-residuals)"}
qr <- gfplot::qres_tweedie(cpue_model, response = "cpue")
gfplot::plot_qres_histogram(qr)
```

```{r, fig.cap="3CD eg.", eval=FALSE}
readRDS(here::here("report/cpue-cache/petrale-sole-3CD-model.rds")) %>%
  gfplot::qres_tweedie(response = "cpue") %>%
  gfplot::plot_qres_histogram()
```


\clearpage


<!-- TODO: Make sure all figures are referenced as fig or figure -->

<!-- TODO: Redo this cpue section with the Tweedie model -->

<!--



<<cpue-coefs-eg, fig.cap="Example model coefficients for CPUE index standardization for Petrale Sole in area 3CD. ``Bin.'' (black) refers to the binary component model and ``Pos.'' (blue) refers to the positive component model. The white dots represent the parameter estimates and the thick and thin line segments represent 50\\% and 95\\% confidence intervals. Each panel represents a set of coefficients for each factor level. The reference level has been set to the most common bin and the shown coefficient estimates are effects with respect to this reference level. For example, the month effects represent differences between the indicated month and January (the omitted reference level).", fig.asp=1.1, warning=FALSE, message=FALSE, fig.width=13>>=
gfplot::plot_cpue_index_coefs(cpue_model, type = "tweedie")
@

<<cpue-sim-eg, results='hide', message=FALSE, warning=FALSE>>=
set.seed(123)
fit1 <- gfplot:::sim_cpue_index(
  make_plots = TRUE,
  n_samples = 15,
  n_vessels = 10
)
fit2 <- gfplot:::sim_cpue_index(
  make_plots = TRUE,
  n_samples = 15,
  n_vessels = 10
)
@

<<cpue-sim-cross-val, fig.cap="Parameter estimate validation for CPUE index standardization models fit to two example simulated data sets. Each panel shows the true simulated parameter value on the horizontal axis and the estimated parameter value along with a 95\\% confidence interval on the vertical axis. ``Bin.'' represents parameters from the binary model and ``Pos.'' represents parameters from the positive component model. The diagonal line indicates a one-to-one relationship.", fig.asp=0.55>>=
cowplot::plot_grid(fit1$cross_val, fit2$cross_val, nrow = 1, align = "h")
@

<<cpue-sim-ts-val, fig.cap="Annual CPUE index validation for standardization models fit to two example simulated data sets. Red crosses indicate true values, open the black circles represent the estimated values, and vertical line segments represent 95\\% confidence intervals.", fig.asp=0.35>>=
cowplot::plot_grid(fit1$ts_check, fit2$ts_check, nrow = 1, align = "h")
@

-->

## MATURITY OGIVES {#sec:maturity-models}

We fit maturity ogives as logistic regressions of maturity (mature vs.\ not
mature) against length or age:

\begin{align}
y_i &\sim \mathrm{Binomial}(\pi_i)\\
\mathrm{logit} \left( \pi_i \right) &= \beta_0 + \beta_1 x_i + \beta_2 F_i
\end{align}
where $y_i$ represents a 1 if fish $i$ is considered mature and a 0 if fish $i$
is considered immature. The $\beta$ parameters represent estimated coefficients,
$x_i$ represents either the length or age of fish $i$, and $F_i$ represents
a binary predictor that is 1 if the fish is female and 0 if the fish is male.
The variable $\pi_i$ represents the expected probability of fish $i$ being
mature. We only fit these models if there are at least 20 mature males, 20
immature males, 20 mature females, and 20 immature females to ensure reasonably
representative sampling and sufficient sample sizes.

## LENGTH-AGE MODELS {#sec:length-age-models}

We fit von Bertalanffy length-age growth models [@vonbertalanffy1938] with
Stan [@rstan2018] as:

\begin{equation}
  L_i \sim \operatorname{Log-normal}
  \left( \log(l_\mathrm{inf} (1 - \exp(-k (A_i - t_0)))), \sigma \right)
\end{equation}

where $L_i$ and $A_i$ represent the length and age of fish $i$,
$l_\mathrm{inf}$, $k$, and $t_0$ represent the von Bertalanffy growth
parameters, and $\sigma$ represents the log standard deviation or scale
parameter. We fit the models with the following priors:

\begin{align}
  k &\sim \mathrm{Normal}\left(0, 2\right)[0, \infty]\\
  l_\mathrm{inf} &\sim  \mathrm{Normal} \left(0, \varphi \right)[0, \infty]\\
  \sigma &\sim  \operatorname{Student-t}\left(3, 0, 2 \right)[0, \infty]\\
  t0 &\sim  \mathrm{Normal}(0, 20)
\end{align}

where $\varphi$ was set to twice the 99\% quantile of observed lengths for that
species. This ensures that the $l_\mathrm{inf}$ prior is on an appropriate scale
for a given species. These weakly informative priors were helpful when fitting
these nonlinear models to a large number of species making it is difficult to
adjust the optimization procedure on a species-by-species basis. For speed, the
model fits shown in this synopsis report are derived from the mode of the
marginal posterior distributions (MPD) as opposed to from full Markov chain
Monte Carlo (MCMC) sampling.

## LENGTH-WEIGHT MODELS {#sec:length-weight-models}

We fit the length-weight models as robust linear regressions of log(length) on
log(weight) using the `MASS::rlm()` function 'M'-estimator method
[@venables2002]. This approach downweights the influence of outlying values
and helps generate reasonable model fits across all species without handpicking
outlying measurements to discard. The model can be written as:

\begin{equation}
  W_i = a \cdot L_i^b \cdot e_i,
\end{equation}
with $W_i$ and $L_i$ representing the weight and length for fish $i$ and $e_i$
representing error that is given some distribution such as lognormal or Gamma.
The variables $a$ and $b$ represent the estimated length-weight parameters.
Following the common convention, we fit the model as:
\begin{equation}
  \log (W_i) \sim \mathrm{Normal} (\log (a + b L_i), \sigma),
\end{equation}
with a robust algorithm being substituted for the usual normal distribution as
written here.

## GFPLOT PACKAGE

We developed the gfplot R package to conduct all the data extraction, data
manipulation, model fitting, and plotting in the data synopsis report. The
package is designed to be modular so it can be used in various capacities for
other groundfish analyses (Figure \ref{fig:gfplot-web}). For example, the
package is intended to facilitate pulling data directly into analyses for the
forthcoming management procedure framework for data-limited and data-moderate
groundfish stocks. A brief summary will follow.

```{r gfplot-web, fig.cap="An illustration of the gfplot functions and how they interact. \texttt{get} functions extract raw data from the relational databases, \texttt{tidy} and \texttt{fit} functions manipulate the data or fit statistical models, and \texttt{plot} functions take the output from the tidying or fitting functions to make visualizations.", out.width="4in"}
knitr::include_graphics(here::here("report", "report-rmd", "figure",
    "function-web.pdf"), dpi = NA)
```

\clearpage
