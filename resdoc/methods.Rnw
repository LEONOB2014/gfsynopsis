% !TEX root = gf-synopsis.Rnw

\section{METHODS}

\subsection{DATA EXTRACTION}

For the annual data synopsis report, commercial and research survey data are
plotted to visualize the available data for groundfish species. Commercial
and research catch, effort, and biological data are archived by the Groundfish
Data Unit (Fisheries and Oceans Canada, Science Branch, Pacific Region) and
housed in a number of relational databases. Historical commercial catch and
effort data from 1954--2006/2007 are housed in GFCatch, PacHarvTrawl,
PacHarvHL, and PacHarvSable depending on the fishery and time period.
Modern (2006/2007 to present) commercial catch data are housed in GFFOS,
a groundfish-specific ``view'' of the Fishery Operations System (FOS) database
(Fisheries and Oceans Canada, Fisheries and Aquaculture Management, Pacific
Region).  Research survey data and commercial biological data from the 1940s
to present are housed in GFBio, the Groundfish Biological Samples database.

Functions were developed within the \texttt{gfplot} package to automate
data extraction from these databases in a consistent, reproducible manner.
These functions extract data using SQL queries, developed with support from
the Groundfish Data Unit, and the data are formatted to feed directly into
other functions in the package to allow for a fully automated procedure.
Some filtering is performed within the SQL queries to restrict the data
extracted.

Commercial catch data are extracted with \texttt{get-catch}.
All landings and discards are extracted by species, fishery sector, gear type
and year in kg and are not filtered in any way (Table~\ref{tab:sql-catch}).
Species names are specified as an argument to the function by the user.

Commercial trawl catch per unit effort (CPUE) index data are
extracted using \texttt{get-CPUE-index} and are filtered to include only
records with valid start and end dates (Table ~\ref{tab:sql-cpue-index}).
Catch (kg) and effort (exptressed in hours), year, gear type and Pacific Fishery
Management Area (PFMA) are extracted for each tow.
Gear type, PFMA and minimum year are given as arguments and are set at
defaults of bottom trawl, all areas and 1996, respectively.

Commercial trawl spatial CPUE data are extracted using \texttt{get-cpue-spatial},
pulling out latitude, longitude, gear type, catch (kg) and tow time (hours)
for every tow by species.
The data are filtered to remove records with erroneous latitude and longitude
values, and to include only records from the groundfish trawl sector since 2012
when the trawl footprint was implemented (Table~\ref{tab:sql-cpue-spatial}).
Species names are given as an argument to the function.

Spatial longline CPUE data are extracted using \texttt{get-cpue-spatial-ll} which
pulls out latitude and longitude, gear type, catch (pieces) and years for all
fishing events (sets, as a unit of effort) by species.
Data are filtered to remove records with erroneous latitude and
longitude data, and for records with longline gear and from and including 2008
after the implementation of rockfish conservation areas
(Table ~\ref{tab:sql-cpue-spatial-ll}).
CPUE is represented by catch in pieces per fishing event (set)
Species names are given as an argument to the function.

Survey biomass index data are extracted with \texttt{get-survey-index}.
Calculated bootstrapped biomass, year and survey series identification code
(ssid) are filtered for active records of the calculated biomass in the
database (Table ~\ref(tab:sql-survey-index}).
Species and survey series identification code (ssid) are given as arguments
to the function.

Biological data are extracted using \texttt{get-survey-samples} and
\texttt{get-comm-samples} for research survey and commercial samples,
respectively.
Records of all biological samples are extracted by species, including
available length, weight, age and maturity data.
Records include available metadata including PFMA, gear type, ssid, sample date,
survey identification code (sid) and sampling protocol codes
for maturity and ageing data.
Data are filtered by the \texttt{TRIP\_SUBTYPE\_CODE} to extract either survey
or commercial samples (Table~\ref{tab:sql-bio-samp}).
In addition, samples are restricted to unsorted samples with
\texttt{SPECIES_CATEGORY_CODE} and \texttt{SAMPLE_SOURCE_CODE} to avoid bias
from inclusion of sorted, stratified or selected samples.
Survey samples are also filtered for only total or random samples.

The ageing precision data are extracted with \texttt{get-age-precision}.
Data are filtered to bring in only records for which a secondary (precision)
reading was performed by a different technician in addition to the primary
reading (Table~\ref{tab:sql-age-precision})




\subsection{COMMERCIAL FISHERY CATCHES}

% \begin{figure}[htbp]
% \centering
% \includegraphics[height=2.75in]{../catches/pacific-ocean-perch.pdf}
% \caption{Pacific Ocean Perch catches.}
% \end{figure}

The plot shows the sum of landings (weight of landings plus weight of discards)
aggregated each year within bottom trawl, midwater trawl, hook and line, and
trap categories. I aggregated other minor categories, including \texttt{unknown}
and generic \texttt{trawl} into their own category. These generally represent
a very small quantity of catches. I combined discarded weight across all the
categories. I did not include fish pieces in the current plot, which for the
most part means that hook and line discards are ignored.

Years before 1996 are shaded to indicate they are less reliable.

% Do we want to try and account for hook and line discards? Do we want to show
% trawl and hook and line / traps separately?

\subsection{COMMERCIAL CATCH PER UNIT EFFORT}

% \begin{figure}[htbp]
% \centering
% \includegraphics[height=3.8in]{../cpue/pacific-ocean-perch.pdf}
% \caption{Pacific Ocean Perch CPUE for the groundfish bottom trawl sector. Shown
%   is the geometric mean within each hexagon cell since 2013.}
% \end{figure}

These represent catches in weight (landings + discards) per unit effort (time) for the
groundfish trawl fleet.

The plots show all CPUE from 2013 onwards since the trawl footprint was frozen
in April 2012.

Hexagon cells are X km wide and show the geometric mean of CPUE as indicated by
the shading of each cell. Cells must have at least three unique vessels to be
shown. I am also only showing any data if there are at least 5 hexagon cells to
show.

The map shows depth contours at 100m, 200m, and 500m (in increasingly slightly
darker shades of grey).

The coloured rectangles indicate the subplot regions in the spatial survey plots.

We may want to show the trawl footprint boundaries.

We could pick a finer or coarser cell size. I picked something to approximately
match what is usually used in groundfish stock assessment research documents.
It's a balance between fine-scale accuracy and being able to see the patterns on
a relatively small figure.

\subsection{AVAILABLE BIOLOGICAL SAMPLES} \label{sec:bio-samples}

% \begin{figure}[htbp]
% \centering
% \includegraphics[height=2.45in]{../synop/dat-syn-pacific-ocean-perch.pdf}
% \caption{Pacific Ocean Perch available biological samples.}
% \end{figure}

The shading of the grid cells indicates the number of samples for a given year
and data type available across all surveys or commercial sources. The cell in
each panel with the largest value has its value indicated in text (rounded to an
appropriate clean number). The colour scales are independent between the
commercial and survey panels.

Note that the survey samples come from all survey data in the GFBioSQL
database, not just the surveys focused on elsewhere in the document.

% I'm currently only counting specimens which have a \texttt{sex} value of male or
% female. I'm not sure if there are some stocks where it is difficult to assign
% a sex but we do still want the biological measurements.

We could also consider showing the counts for male and female, or for female
only, which might make sense for the purposes of data-limited assessments that
do not model the two separately.

\subsection{LENGTH DISTRIBUTIONS}

% \begin{figure}[htbp]
% \centering
% \includegraphics[height=4in]{../joy/pacific-ocean-perch-joy.pdf}
% \caption{Pacific Ocean Perch length distributions shown as probability densities
%   of ``Joy'' plots.. Coloured represents females. Grey represents males.}
% \end{figure}

These are probability density plots for the fish lengths by year and survey.
Effectively these are a continuous version of a histogram.

Coloured represents females. Grey represents males. I've been trying to figure
out what the best way to indicate that on the plot is.

The plots are only showing probability densities for year-sex-survey
combinations with at least X fish samples. Otherwise, the probability density
plots can start reflecting more noise than signal in the data.

These could be done instead as histograms or as bubble plots, but it is
challenging to fit as much information in such a small space with these other
types of plots.

\subsection{SPATIAL MODELLING OF SYNOPTIC TRAWL SURVEY DATA}

% \begin{figure}[htbp]
% \centering
% % \includegraphics[height=4in]{../spatial-survey/pacific-ocean-perch.pdf}
% \caption{Pacific Ocean Perch biomass estimates from surveys.}
% \end{figure}

The data were extracted from GFBioSQL with the procedure
\texttt{proc\_catmat\_2011}, which is used to generate the data for the usual
stratum-based bootstrap procedure to calculate the biomass indices from these
trawl surveys.

Here I am fitting Bayesian generalized linear mixed effects models with Gaussian
random fields to estimate expected biomass density on the surface covering the
entirety of the survey boundaries. I fit the models with the glmmfields
R package I've been working on
(\url{https://github.com/seananderson/glmmfields}). The Gaussian
random field describes a wiggly surface of unexplained spatial pattern (the
``random effects'') in the response variable (here biomass of fish or
probability of observing a given fish species in a survey tow) beyond that which
can be described by the included ("fixed effect") predictors (here a quadratic
effect of bottom depth). Gaussian random fields describe random effects drawn
from a multivariate normal distribution with some estimated covariance
structure. The glmmfields package uses a predictive process approach where
a limited number of ``knots'' are modelled and these are projected to the data
locations as part of the fitting process. This makes the analysis of large
spatial data sets possible.

See Appendix \ref{sec:spatial-app} for details on the methods.

At this point I'm only using bottom depth as a predictor but there's no reason
why we couldn't include other predictors such as bottom temperature and
substrate type.

I still need to tweak the interpolation algorithm to go from the
bathymetry grid layer to the locations of the grid cells in the final
projection (I think it's introducing a bit of `roughness' right now). I'm using
actual tow depth for the observed data and the depth data from `PBSdata::bctopo`
for the projections. Originally I was using a NOAA dataset, but it didn't match
the trawl depths as closely. It sounds like another division of DFO might be
developing an even better version we could use.

There are separate models for the presence or absence of a given species in
a tow and for the density if they are observed. These are then combined after by
multiplying the probability of observation with the density conditional on being
observed and are projected onto a fine-scale grid encompassing the full region
of the survey polygon.

I am only fitting the spatial models if at least 10\% of the survey tows from
a given survey caught that species that year. Otherwise, there is very little
data to estimate the positive density component. In these cases, I just show the
raw tow data and do not add the colour shading for the predicted biomass density.

I am only showing the predicted biomass density for fine-scale grid cells within
the range of depth for that survey in that year (extending an extra 5m shallower
and deeper; hence the patches of white). This avoids extrapolating the
density-presence and density-biomass relationships. This becomes important
because there are a couple points in the survey polygons that get very close to
land, even crossing slightly. Extrapolating the quadratic relationship can
predict very high densities for these grid cells and distort the colour
scheme.

Crosses indicate tows that did not catch that species. Circles indicate tows
that did catch that species and the area of the circle is proportional to the
density.

We may want to add point size and colour legends to these. We may also want to
scale the colours and point sizes so that they are consistent across the
different survey panels. Right now there is no way to get a feeling for the
relative abundance of species between the survey areas. The only larger scale
spatial indicator is the trawl CPUE.

We would want to emphasize that these spatial predictions are for visualization
purposes only at this point. We'd want to do a lot more investigation on
a stock-by-stock basis before believing them too strongly.

\subsection{BIOMASS SURVEY INDEX TRENDS}

% \begin{figure}[htbp]
% \centering
% % \includegraphics[height=3.4in]{../sparks/pacific-ocean-perch.pdf}
% \caption{Pacific Ocean Perch survey biomass index trends.}
% \end{figure}

These show the median and 95\% bootstrap confidence intervals on the survey
biomass trends through time. Each trend is scaled so that the maximum upper
confidence interval reaches the top of the plot. We could consider plotting them
with consistent absolute biomass on the y-axis, but that depends how much we
trust these values relative to each other.

\subsection{LENGTH-AGE AND LENGTH-WEIGHT MODEL FITS}

% \begin{figure}[htbp]
% \centering
% % \includegraphics[height=3.35in]{../vb/pacific-ocean-perch.pdf}
% \caption{Pacific Ocean Perch length-age and length-weight model fits.}
% \end{figure}

I am fitting these models to survey data only currently. I should likely include
commercial samples as well. At least the unsorted samples.

I only fit models in cases where there were more than 100 fish samples for
a given species-sex combination.

The von Bertalanffy models were fit with Stan (details to follow):

\begin{equation}
  L_i \sim \mathrm{lognormal} \left( \log(l_\mathrm{inf} (1 - \exp(-k (A_i - t_0)))), \sigma \right)
\end{equation}

where $L_i$ and $A_i$ represent the length and age of fish $i$,
$l_\mathrm{inf}$, $k$, and $t_0$ represent the von Bertalanffy growth
parameters, and $\sigma$ represents the log standard deviation or scale
parameter. The models were fit with the following priors:

\begin{align}
  k &\sim \mathcal{N}(0, 1)[0, \infty]\\
  l_\mathrm{inf} &\sim  \mathcal{N}(0, \varphi)[0, \infty]\\
  \sigma &\sim  \mathcal{N}(0, 1)[0, \infty]\\
  t0 &\sim  \mathcal{N}(0, 20)
\end{align}

where $\varphi$ was set to twice the 99\% quantile of observed lengths for that
stock. This ensures that the $l_\mathrm{inf}$ prior is on an appropriate scale
for a given stock.

These weakly informative priors and the Bayesian framework in general are
helpful when fitting these nonlinear models to a large number of stocks where
maximum likelihood methods can give nonsensical results for some stocks and it
is difficult to adjust the optimization procedure on a stock-by-stock basis. I'm
open to modifying the priors, are trying the same models in TMB. Straight
optimization to the mode of the posterior distributions (i.e.\ no MCMC) in Stan
was having problems for some stocks.

I fit the length-weight models as robust linear regressions of log(length)
on log(weight) (details to follow, \texttt{MASS::rlm()} function).

We may want some filtering iteration where we exclude data points that are
obviously measurement or data-entry errors based on enormous residual values.
This could remove the need for the \textit{robust} linear regression.

All the points are the same colour right now. We could colour them by male and
female. If there are more than 2000 fish samples for a given stock, I randomly
sample 2000 fish to plot. This is just to avoid plotting an excessive number of
dots, which generates very large PDF files.

\subsection{AGE BUBBLE PLOTS}

% \begin{figure}[htbp]
% \centering
% % \includegraphics[height=4in]{../bubbles/pacific-ocean-perch.pdf}
% \caption{Pacific Ocean Perch age bubble plots.}
% \end{figure}

The area of the circles is proportional to the number of fish at a given age in
a given year for a given survey. The bubble scale is constant for a given
stock but is independent across stocks so that the maximum area of a bubble
is the same across stocks. We could instead scale them within each survey.

This, and the length plots, are cases where we may want to select a certain
number of surveys that have the most data for a given stock since there are
cases where these four synoptic surveys are not the best available data for
a given stock.

\begin{table}[htp]
\centering
\caption{Description of filters in SQL queries extracting commercial sample data from \texttt{GFBio}}
\label{tab:sql-comm-samp}
{\tabulinesep=1.6mm
\begin{tabu}{>{\raggedright\arraybackslash}m{2in}>{\raggedright\arraybackslash}m{2in}>{\raggedright\arraybackslash}m{2in}}
\toprule
SQL Query                                                                                    & Filters                                                                                       & Rationale                                                                                                                                 \\
\midrule
Extracting commercial biological data from \texttt{GFBio} with \texttt{get-comm-samples.sql} & Filtered out \texttt{TRIP\_SUBTYPE\_CODE} \texttt{2, 3} (research trips)                      & To extract only commercial data                                                                                                           \\
                                                                                             & Filtered for \texttt{SAMPLE\_TYPE\_CODE} \texttt{1, 2, 6, 7, 8} (random or total)             & To extract only those records of sample type 'random' or 'total'                                                                          \\
                                                                                             & Filtered for \texttt{SPECIES\_CATEGORY\_CODE} \texttt{NULL, 1, 3, 4, 5, 6, 7}                 & To remove samples sorted on unknown criteria (includes remains and fish heads from longline samples)                          \\
                                                                                             & Filtered for \texttt{SAMPLE\_SOURCE\_CODE} \texttt{NULL, 1, 2, 3}                             & To extract both sorted and unsorted samples for later filtration for desired analysis (removes stomach contents samples)                                                                        \\
\bottomrule
\end{tabu}}
\end{table}


\begin{table}[htp]
\centering
\caption{Description of filters in SQL queries extracting research survey sample data from \texttt{GFBio}}
\label{tab:sql-bio-samp}
{\tabulinesep=1.6mm
\begin{tabu}{>{\raggedright\arraybackslash}m{2in}>{\raggedright\arraybackslash}m{2in}>{\raggedright\arraybackslash}m{2in}}
\toprule
SQL Query                                                                                    & Filters                                                                              & Rationale                                                                                                   \\
\midrule
Extracting survey biological data from \texttt{GFBio} with \texttt{get-survey-samples.sql}   & Filtered for \texttt{TRIP\_SUBTYPE\_CODE} \texttt{2, 3} (research trips)             & To extract only research data                                                                               \\
                                                                                             & Filtered for \texttt{SAMPLE\_TYPE\_CODE} \texttt{1, 2} (random or total)             & To extract only those records of sample type 'random' or 'total'                                            \\
                                                                                             & Filtered for \texttt{SPECIES\_CATEGORY\_CODE} \texttt{1, NULL} (unsorted catches)    & To extract samples only from catches which were unsorted                                                    \\
                                                                                             & Filtered for \texttt{SAMPLE\_SOURCE\_CODE} \texttt{1, NULL} (unsorted samples)       & To extract only samples which were unsorted to avoid sampling bias                                          \\
\bottomrule
\end{tabu}}
\end{table}

\begin{table}[htp]
\centering
\caption{TODO: CAPTION HERE}
\label{tab:sql-cpue-index}
{\tabulinesep=1.6mm
\begin{tabu}{>{\raggedright\arraybackslash}m{2in}>{\raggedright\arraybackslash}m{2in}>{\raggedright\arraybackslash}m{2in}}
\toprule
SQL Query                                                                                                                        & Filters                                                                                                            & Rationale                                                              \\
\midrule
Extracting commercial trawl catch per unit effort (kg/hr) from \texttt{GFFOS.GF\_MERGED\_CATCH} with \texttt{get-cpue-index.sql} & Filtered for \texttt{END\_DATE} \texttt{IS NOT NULL} AND {START\_DATE} \texttt{IS NOT NULL}                        & To remove erroneous date records                                       \\
\bottomrule
\end{tabu}}
\end{table}

\begin{table}[htp]
\centering
\caption{TODO: CAPTION HERE}
\label{tab:sql-cpue-spatial}
{\tabulinesep=1.6mm
\begin{tabu}{>{\raggedright\arraybackslash}m{2in}>{\raggedright\arraybackslash}m{2in}>{\raggedright\arraybackslash}m{2in}}
\toprule
SQL Query                                                                                                     & Filters                                                                                                                                   & Rationale                                                              \\
\midrule
Extracting commercial trawl spatial catch per unit effort (kg/hr) from \texttt{GFFOS.GF\_D\_OFFICIAL\_CATCH} with \texttt{get-cpue-index.sql}& Filtered for \texttt{LAT} between 47.8 and 55 and LON between -135 and -122                                & To remove erroneous location records                                   \\
                                                                                                                                     & Filtered for \texttt{YEAR(BEST\_DATE)} \textgreater2012                                                            & To extract data since the fishery footprint was initiated              \\
                                                                                                                                     & Filtered for \texttt{FISHERY\_SECTOR} \texttt{'GROUNDFISH TRAWL'}                                                  & To select only trawl fishery data                                      \\
                                                                                                                                     & Filtered for (\texttt{LANDED\_ROUND\_KG} + \texttt{TOTAL\_RELEASED\_ROUND\_KG}) \textgreater0                      & To select only fishing events which had a positive catch for a species \\
                                                                                                                                     & Filtered for \texttt{END\_DATE} \textgreater \texttt{START\_DATE} AND \texttt{YEAR(START\_DATE) = YEAR(END\_DATE)} & To remove erroneous date records                                       \\
\bottomrule
\end{tabu}}
\end{table}

\begin{table}[htp]
\centering
\caption{TODO: CAPTION HERE}
\label{tab:sql-get-catch}
{\tabulinesep=1.6mm
\begin{tabu}{>{\raggedright\arraybackslash}m{2in}>{\raggedright\arraybackslash}m{2in}>{\raggedright\arraybackslash}m{2in}}
\toprule
SQL Query                                                                                     & Filters    & Rationale                                                       \\
\midrule
Extract commercial landings from \texttt{GFFOS.GF\_MERGED\_CATCH} with \texttt{get-catch.sql} & No filters & To extract all landings and discards by fishery sector and gear \\
\bottomrule
\end{tabu}}
\end{table}

\begin{table}[htp]
\centering
\caption{TODO: CAPTION HERE}
\label{tab:sql-no filters}
{\tabulinesep=1.6mm
\begin{tabu}{>{\raggedright\arraybackslash}m{2in}>{\raggedright\arraybackslash}m{2in}>{\raggedright\arraybackslash}m{2in}}
\toprule
SQL Query                                                                                           & Filters                           & Rationale                                                                                                                \\
\midrule
Extract commercial landings from \texttt{GFFOS.GF\_MERGED\_CATCH} with \texttt{get-catch.sql}       & No filters                        & To extract all landings and discards by fishery sector and gear                                                          \\
Assign maturity status from \texttt{GFFOS.GFBio} with \texttt{maturity\_assignment.sql}             & No filters                        & Designates maturity code at and above which a sample assessed following a given maturity convention is considered mature \\
\bottomrule
\end{tabu}}
\end{table}

\begin{table}[htp]
\centering
\caption{TODO: CAPTION HERE}
\label{tab:sql-survey-index}
{\tabulinesep=1.6mm
\begin{tabu}{>{\raggedright\arraybackslash}m{2in}>{\raggedright\arraybackslash}m{2in}>{\raggedright\arraybackslash}m{2in}}
\toprule
SQL Query                                                                                     & Filters                            & Rationale                                                      \\
\midrule
Extract bootstrapped survey biomass index from \texttt{GFBio} with \texttt{get-survey-index}  & Filter for ACTIVE\_IND 1          & To extract only active (useable) bootstrapped index records     \\
\bottomrule
\end{tabu}}
\end{table}


\begin{table}[htp]
\centering
\caption{TODO: CAPTION HERE}
\label{tab:sql-age-precision}
{\tabulinesep=1.6mm
\begin{tabu}{>{\raggedright\arraybackslash}m{2in}>{\raggedright\arraybackslash}m{2in}>{\raggedright\arraybackslash}m{2in}}
\toprule
SQL Query                                                                                                 & Filters                                    & Rationale                                                                                                        \\
\midrule
Extract all age readings to determine aging precision from {GFBio} with \texttt{get\_age\_precision.sql}  & filter for AGE\_READING\_TYPE\_CODE 2, 3   & To extract only those aged specimen records which were aged using the break and burn or break and bake methods   \\
\end{tabu}}
\end{table}

